{"cells":[{"cell_type":"code","execution_count":124,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-15T01:53:07.486932Z","iopub.status.busy":"2024-09-15T01:53:07.486377Z","iopub.status.idle":"2024-09-15T01:53:07.492626Z","shell.execute_reply":"2024-09-15T01:53:07.491150Z","shell.execute_reply.started":"2024-09-15T01:53:07.486884Z"},"trusted":true},"outputs":[],"source":["from IPython.display import display\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:07.496093Z","iopub.status.busy":"2024-09-15T01:53:07.495155Z","iopub.status.idle":"2024-09-15T01:53:07.509314Z","shell.execute_reply":"2024-09-15T01:53:07.507988Z","shell.execute_reply.started":"2024-09-15T01:53:07.496032Z"},"trusted":true},"outputs":[],"source":["# Configuration\n","import logging\n","import sys\n","from multiprocessing import cpu_count\n","\n","# Configure logging level\n","logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)\n","\n","# Number of cpu cores used\n","n_jobs = cpu_count()"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:07.537227Z","iopub.status.busy":"2024-09-15T01:53:07.536828Z","iopub.status.idle":"2024-09-15T01:53:07.730971Z","shell.execute_reply":"2024-09-15T01:53:07.729648Z","shell.execute_reply.started":"2024-09-15T01:53:07.537190Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TransactionNumber</th>\n","      <th>UserID</th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Occupation</th>\n","      <th>EducationLevel</th>\n","      <th>MaritalStatus</th>\n","      <th>NumDependents</th>\n","      <th>Income</th>\n","      <th>Expenditure</th>\n","      <th>...</th>\n","      <th>TransactionAmount</th>\n","      <th>MerchantID</th>\n","      <th>TransactionType</th>\n","      <th>TransactionLocation</th>\n","      <th>DeviceType</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>EmailDomain</th>\n","      <th>Terrorism</th>\n","      <th>UserTenure</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8765</td>\n","      <td>70</td>\n","      <td>37</td>\n","      <td>Female</td>\n","      <td>Professional</td>\n","      <td>Bachelor</td>\n","      <td>Widowed</td>\n","      <td>3</td>\n","      <td>28884.43</td>\n","      <td>14610.6100</td>\n","      <td>...</td>\n","      <td>258.1400</td>\n","      <td>M006</td>\n","      <td>Withdrawal</td>\n","      <td>Adelaide</td>\n","      <td>mobile</td>\n","      <td>-31.840233</td>\n","      <td>145.612793</td>\n","      <td>jon44@disposable.com</td>\n","      <td>False</td>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9645</td>\n","      <td>3386</td>\n","      <td>34</td>\n","      <td>Male</td>\n","      <td>Student</td>\n","      <td>High School</td>\n","      <td>Married</td>\n","      <td>4</td>\n","      <td>54919.07</td>\n","      <td>39169.4900</td>\n","      <td>...</td>\n","      <td>34.9400</td>\n","      <td>M002</td>\n","      <td>Withdrawal</td>\n","      <td>Canberra</td>\n","      <td>mobile</td>\n","      <td>-37.020100</td>\n","      <td>144.964600</td>\n","      <td>emilyreese@gmail.com</td>\n","      <td>False</td>\n","      <td>104</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1145</td>\n","      <td>2971</td>\n","      <td>25</td>\n","      <td>Male</td>\n","      <td>Unemployed</td>\n","      <td>Master</td>\n","      <td>Married</td>\n","      <td>2</td>\n","      <td>74728.57</td>\n","      <td>55873.7600</td>\n","      <td>...</td>\n","      <td>323.8200</td>\n","      <td>M008</td>\n","      <td>Purchase</td>\n","      <td>Brisbane</td>\n","      <td>mobile</td>\n","      <td>-31.840233</td>\n","      <td>145.612793</td>\n","      <td>fordevan@gmail.com</td>\n","      <td>False</td>\n","      <td>105</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15308</td>\n","      <td>2925</td>\n","      <td>25</td>\n","      <td>Male</td>\n","      <td>Professional</td>\n","      <td>High School</td>\n","      <td>Married</td>\n","      <td>3</td>\n","      <td>55712.62</td>\n","      <td>34963.1256</td>\n","      <td>...</td>\n","      <td>12.6711</td>\n","      <td>M001</td>\n","      <td>Purchase</td>\n","      <td>Darwin</td>\n","      <td>mobile</td>\n","      <td>-37.020100</td>\n","      <td>144.964600</td>\n","      <td>kathleenlewis@tempmail.com</td>\n","      <td>False</td>\n","      <td>70</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14967</td>\n","      <td>2339</td>\n","      <td>38</td>\n","      <td>Male</td>\n","      <td>Professional</td>\n","      <td>High School</td>\n","      <td>Single</td>\n","      <td>4</td>\n","      <td>53004.70</td>\n","      <td>17004.3978</td>\n","      <td>...</td>\n","      <td>444.8925</td>\n","      <td>M001</td>\n","      <td>Withdrawal</td>\n","      <td>MLB</td>\n","      <td>tablet</td>\n","      <td>-37.020100</td>\n","      <td>144.964600</td>\n","      <td>kristinawhite@gmail.com</td>\n","      <td>False</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 23 columns</p>\n","</div>"],"text/plain":["   TransactionNumber  UserID  Age  Gender    Occupation EducationLevel  \\\n","0               8765      70   37  Female  Professional       Bachelor   \n","1               9645    3386   34    Male       Student    High School   \n","2               1145    2971   25    Male    Unemployed         Master   \n","3              15308    2925   25    Male  Professional    High School   \n","4              14967    2339   38    Male  Professional    High School   \n","\n","  MaritalStatus  NumDependents    Income  Expenditure  ...  TransactionAmount  \\\n","0       Widowed              3  28884.43   14610.6100  ...           258.1400   \n","1       Married              4  54919.07   39169.4900  ...            34.9400   \n","2       Married              2  74728.57   55873.7600  ...           323.8200   \n","3       Married              3  55712.62   34963.1256  ...            12.6711   \n","4        Single              4  53004.70   17004.3978  ...           444.8925   \n","\n","  MerchantID TransactionType  TransactionLocation DeviceType   Latitude  \\\n","0       M006      Withdrawal             Adelaide     mobile -31.840233   \n","1       M002      Withdrawal             Canberra     mobile -37.020100   \n","2       M008        Purchase             Brisbane     mobile -31.840233   \n","3       M001        Purchase               Darwin     mobile -37.020100   \n","4       M001      Withdrawal                  MLB     tablet -37.020100   \n","\n","    Longitude                 EmailDomain  Terrorism  UserTenure  \n","0  145.612793        jon44@disposable.com      False         113  \n","1  144.964600        emilyreese@gmail.com      False         104  \n","2  145.612793          fordevan@gmail.com      False         105  \n","3  144.964600  kathleenlewis@tempmail.com      False          70  \n","4  144.964600     kristinawhite@gmail.com      False          27  \n","\n","[5 rows x 23 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>IsFraud</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   IsFraud\n","0        1\n","1        1\n","2        0\n","3        1\n","4        0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TransactionNumber</th>\n","      <th>UserID</th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Occupation</th>\n","      <th>EducationLevel</th>\n","      <th>MaritalStatus</th>\n","      <th>NumDependents</th>\n","      <th>Income</th>\n","      <th>Expenditure</th>\n","      <th>...</th>\n","      <th>TransactionAmount</th>\n","      <th>MerchantID</th>\n","      <th>TransactionType</th>\n","      <th>TransactionLocation</th>\n","      <th>DeviceType</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>EmailDomain</th>\n","      <th>Terrorism</th>\n","      <th>UserTenure</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11854</td>\n","      <td>963</td>\n","      <td>35</td>\n","      <td>man</td>\n","      <td>Student</td>\n","      <td>Bachelor</td>\n","      <td>Single</td>\n","      <td>4</td>\n","      <td>53733.41</td>\n","      <td>29296.02</td>\n","      <td>...</td>\n","      <td>225.64</td>\n","      <td>M005</td>\n","      <td>Payment</td>\n","      <td>Darwin</td>\n","      <td>Desktop</td>\n","      <td>-37.020100</td>\n","      <td>144.964600</td>\n","      <td>chapmangabriel@outlook.com</td>\n","      <td>True</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2647</td>\n","      <td>1693</td>\n","      <td>23</td>\n","      <td>Male</td>\n","      <td>Professional</td>\n","      <td>Master</td>\n","      <td>Single</td>\n","      <td>2</td>\n","      <td>54856.77</td>\n","      <td>34628.31</td>\n","      <td>...</td>\n","      <td>658.10</td>\n","      <td>M003</td>\n","      <td>Purchase</td>\n","      <td>Darwin</td>\n","      <td>Desktop</td>\n","      <td>-37.020100</td>\n","      <td>144.964600</td>\n","      <td>sjones@gmail.com</td>\n","      <td>True</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5945</td>\n","      <td>4383</td>\n","      <td>44</td>\n","      <td>Male</td>\n","      <td>Student</td>\n","      <td>Bachelor</td>\n","      <td>Single</td>\n","      <td>2</td>\n","      <td>59011.72</td>\n","      <td>33312.46</td>\n","      <td>...</td>\n","      <td>133.59</td>\n","      <td>M004</td>\n","      <td>Purchase</td>\n","      <td>Adelaide</td>\n","      <td>mob</td>\n","      <td>-30.000233</td>\n","      <td>136.209152</td>\n","      <td>woodmaria@yahoo.com</td>\n","      <td>False</td>\n","      <td>95</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6798</td>\n","      <td>1350</td>\n","      <td>40</td>\n","      <td>Male</td>\n","      <td>Student</td>\n","      <td>High School</td>\n","      <td>Married</td>\n","      <td>3</td>\n","      <td>128795.40</td>\n","      <td>67049.00</td>\n","      <td>...</td>\n","      <td>6.74</td>\n","      <td>M008</td>\n","      <td>Withdrawal</td>\n","      <td>Canberra</td>\n","      <td>Mobile</td>\n","      <td>-37.020100</td>\n","      <td>144.964600</td>\n","      <td>rthornton@gmail.com</td>\n","      <td>False</td>\n","      <td>85</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12985</td>\n","      <td>4145</td>\n","      <td>18</td>\n","      <td>Male</td>\n","      <td>Professional</td>\n","      <td>Bachelor</td>\n","      <td>Married</td>\n","      <td>3</td>\n","      <td>44506.03</td>\n","      <td>22856.31</td>\n","      <td>...</td>\n","      <td>15.67</td>\n","      <td>M008</td>\n","      <td>Transfer</td>\n","      <td>Perth</td>\n","      <td>Tablet</td>\n","      <td>-20.917574</td>\n","      <td>142.702789</td>\n","      <td>daniel61@outlook.com</td>\n","      <td>True</td>\n","      <td>102</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 23 columns</p>\n","</div>"],"text/plain":["   TransactionNumber  UserID  Age Gender    Occupation EducationLevel  \\\n","0              11854     963   35    man       Student       Bachelor   \n","1               2647    1693   23   Male  Professional         Master   \n","2               5945    4383   44   Male       Student       Bachelor   \n","3               6798    1350   40   Male       Student    High School   \n","4              12985    4145   18   Male  Professional       Bachelor   \n","\n","  MaritalStatus  NumDependents     Income  Expenditure  ...  \\\n","0        Single              4   53733.41     29296.02  ...   \n","1        Single              2   54856.77     34628.31  ...   \n","2        Single              2   59011.72     33312.46  ...   \n","3       Married              3  128795.40     67049.00  ...   \n","4       Married              3   44506.03     22856.31  ...   \n","\n","   TransactionAmount MerchantID TransactionType  TransactionLocation  \\\n","0             225.64       M005         Payment               Darwin   \n","1             658.10       M003        Purchase               Darwin   \n","2             133.59       M004        Purchase             Adelaide   \n","3               6.74       M008      Withdrawal             Canberra   \n","4              15.67       M008        Transfer                Perth   \n","\n","  DeviceType   Latitude   Longitude                 EmailDomain  Terrorism  \\\n","0    Desktop -37.020100  144.964600  chapmangabriel@outlook.com       True   \n","1    Desktop -37.020100  144.964600            sjones@gmail.com       True   \n","2        mob -30.000233  136.209152         woodmaria@yahoo.com      False   \n","3     Mobile -37.020100  144.964600         rthornton@gmail.com      False   \n","4     Tablet -20.917574  142.702789        daniel61@outlook.com       True   \n","\n","   UserTenure  \n","0          39  \n","1          65  \n","2          95  \n","3          85  \n","4         102  \n","\n","[5 rows x 23 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>IsFraud</th>\n","    </tr>\n","    <tr>\n","      <th>TransactionNumber</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   IsFraud\n","TransactionNumber         \n","1                        0\n","2                        0\n","3                        1\n","4                        1\n","5                        0"]},"metadata":{},"output_type":"display_data"}],"source":["# Load Data\n","\n","import pandas as pd\n","\n","# Read the CSV file while skipping column 15\n","x_train = pd.read_csv('/kaggle/input/datathon-cleaned/inter-uni-datathon-2024-nsw/train.csv', usecols=range(23))\n","\n","y_train = pd.read_csv('/kaggle/input/datathon-cleaned/inter-uni-datathon-2024-nsw/train.csv', usecols=[23])\n","\n","x_test = pd.read_csv('/kaggle/input/datathon-cleaned/inter-uni-datathon-2024-nsw/test.csv', usecols=range(23))\n","\n","submission = pd.read_csv('/kaggle/input/datathon-cleaned/inter-uni-datathon-2024-nsw/sample_submission.csv', index_col=0)\n","\n","display(x_train.head())\n","display(y_train.head())\n","\n","display(x_test.head())\n","\n","display(submission.head())"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:07.733365Z","iopub.status.busy":"2024-09-15T01:53:07.732982Z","iopub.status.idle":"2024-09-15T01:53:31.471231Z","shell.execute_reply":"2024-09-15T01:53:31.469834Z","shell.execute_reply.started":"2024-09-15T01:53:07.733325Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   TransactionNumber  UserID   Age  Gender  Occupation  EducationLevel  \\\n","0             8765.0    70.0  37.0     0.0         0.0             0.0   \n","1             9645.0  3386.0  34.0     1.0         1.0             1.0   \n","2             1145.0  2971.0  25.0     1.0         2.0             2.0   \n","3            15308.0  2925.0  25.0     1.0         0.0             1.0   \n","4            14967.0  2339.0  38.0     1.0         0.0             1.0   \n","\n","   MaritalStatus  NumDependents    Income  Expenditure  ...  \\\n","0            0.0            3.0  28884.43   14610.6100  ...   \n","1            1.0            4.0  54919.07   39169.4900  ...   \n","2            1.0            2.0  74728.57   55873.7600  ...   \n","3            1.0            3.0  55712.62   34963.1256  ...   \n","4            2.0            4.0  53004.70   17004.3978  ...   \n","\n","   TransactionAmount  MerchantID  TransactionType  TransactionLocation  \\\n","0           258.1400         6.0              2.0                  1.0   \n","1            34.9400         2.0              2.0                  2.0   \n","2           323.8200         8.0              1.0                  3.0   \n","3            12.6711         1.0              1.0                  4.0   \n","4           444.8925         1.0              2.0                  5.0   \n","\n","   DeviceType   Latitude   Longitude  EmailDomain  Terrorism  UserTenure  \n","0         0.0 -31.840233  145.612793          6.0        0.0       113.0  \n","1         0.0 -37.020100  144.964600          1.0        0.0       104.0  \n","2         0.0 -31.840233  145.612793          1.0        0.0       105.0  \n","3         0.0 -37.020100  144.964600          5.0        0.0        70.0  \n","4         3.0 -37.020100  144.964600          1.0        0.0        27.0  \n","\n","[5 rows x 23 columns]\n","   TransactionNumber  UserID   Age  Gender  Occupation  EducationLevel  \\\n","0            11854.0   963.0  35.0     1.0         1.0             0.0   \n","1             2647.0  1693.0  23.0     1.0         0.0             2.0   \n","2             5945.0  4383.0  44.0     1.0         1.0             0.0   \n","3             6798.0  1350.0  40.0     1.0         1.0             1.0   \n","4            12985.0  4145.0  18.0     1.0         0.0             0.0   \n","\n","   MaritalStatus  NumDependents     Income  Expenditure  ...  \\\n","0            2.0            4.0   53733.41     29296.02  ...   \n","1            2.0            2.0   54856.77     34628.31  ...   \n","2            2.0            2.0   59011.72     33312.46  ...   \n","3            1.0            3.0  128795.40     67049.00  ...   \n","4            1.0            3.0   44506.03     22856.31  ...   \n","\n","   TransactionAmount  MerchantID  TransactionType  TransactionLocation  \\\n","0             225.64         5.0              0.0                  4.0   \n","1             658.10         3.0              1.0                  4.0   \n","2             133.59         4.0              1.0                  1.0   \n","3               6.74         8.0              2.0                  2.0   \n","4              15.67         8.0              3.0                  9.0   \n","\n","   DeviceType   Latitude   Longitude  EmailDomain  Terrorism  UserTenure  \n","0         2.0 -37.020100  144.964600          2.0        1.0        39.0  \n","1         2.0 -37.020100  144.964600          1.0        1.0        65.0  \n","2         1.0 -30.000233  136.209152          3.0        0.0        95.0  \n","3         1.0 -37.020100  144.964600          1.0        0.0        85.0  \n","4         3.0 -20.917574  142.702789          2.0        1.0       102.0  \n","\n","[5 rows x 23 columns]\n"]}],"source":["# EDA\n","\n","import pandas as pd\n","from sklearn.impute import SimpleImputer\n","\n","def preprocess(df):\n","    # Fix gender\n","    gender_mapping = {'he': 'Male', 'she': 'Female', 'fem': 'Female', 'woman': 'Female', 'man': 'Male', 'isnotmale': 'Female', 'isnotfemale': 'Male'}\n","    df['Gender'] = df['Gender'].replace(gender_mapping)\n","    \n","    # Map occupation to numerical values\n","    df['Occupation'] = df['Occupation'].map({'Professional': 0, 'Student': 1, 'Unemployed': 2, 'Retired': 3})\n","    \n","    # Map education to numerical values\n","    df['EducationLevel'] = df['EducationLevel'].map({'Bachelor': 0, 'High School': 1, 'Master': 2, 'PhD': 3})\n","    \n","    # Map marital status to numerical values \n","    df['MaritalStatus'] = df['MaritalStatus'].map({'Widowed': 0, 'Married': 1, 'Single': 2, 'Divorced': 3})\n","    \n","    # Fix age values - take abs of first 2 digit\n","    df['Age'] = df['Age'].abs().astype(str).str[:2].astype(int)\n","    \n","    # Fix DeviceType\n","    df['DeviceType'] = df['DeviceType'].replace({\n","        'mob': 'Mobile', 'galaxys7': 'Mobile', 'iphone 15': 'Mobile', 'smartphone': 'Mobile', 'android': 'Mobile',\n","        'desktop': 'Desktop', 'laptop': 'Desktop', 'tablet': 'Tablet', 'ipad': 'Tablet'\n","    })\n","\n","    # Convert DeviceType to numerical values, replace missing values with 0\n","    df['DeviceType'] = df['DeviceType'].map({'Mobile': 1, 'Desktop': 2, 'Tablet': 3})\n","    df['DeviceType'] = df['DeviceType'].fillna(0)  # Handle missing values specifically for DeviceType\n","    \n","    # Fix Location\n","    df['TransactionLocation'] = df['TransactionLocation'].replace({\n","        'Cbr': 'Canberra', 'Melb': 'Melbourne', 'Mel': 'Melbourne', 'MLB': 'Melbourne', 'BNE': 'Brisbane', \n","        'Melburn': 'Melbourne', 'adl': 'Adelaide', 'Hbt': 'Hobart', 'SYD': 'Sydney', 'Drw': 'Darwin', \n","        'Pth': 'Perth', 'HBT': 'Hobart', 'Bne': 'Brisbane', 'DRW': 'Darwin', 'Adl': 'Adelaide', \n","        'CBR': 'Canberra', 'PTH': 'Perth', 'Syd': 'Sydney'\n","    })\n","\n","    # Map TransactionLocation to numerical values\n","    location_mapping = {\n","        'Adelaide': 1, 'Canberra': 2, 'Brisbane': 3, 'Darwin': 4, 'Melbourne': 5, \n","        'Sydney': 6, 'Hobart': 7, 'Adelaide Sydney': 8, 'Perth': 9\n","    }\n","    df['TransactionLocation'] = df['TransactionLocation'].map(location_mapping).fillna(0).astype(int)\n","    \n","    # Handle known invalid formats first\n","    df['TransactionTime'] = df['TransactionTime'].replace({\n","        r'(\\d{2})/(\\d{2})/(\\d{4})': r'\\1:\\2:00',  # 04/23/2003 -> 04:23:00\n","        r'(\\d{2})/(\\d{2})/(\\d{2})': r'\\1:\\2:\\3'   # 04/38/42 -> 04:38:42\n","    }, regex=True)\n","\n","    # Function to convert different time formats into 24-hour format\n","    def convert_to_24hr_format(time_val):\n","        try:\n","            # Handle AM/PM times (e.g., '8:23:18 AM', '5:51:01 PM')\n","            return pd.to_datetime(time_val, format='%I:%M:%S %p').strftime('%H:%M:%S')\n","        except (ValueError, TypeError):\n","            try:\n","                # Handle already 24-hour formatted times (e.g., '08:23:18', '17:51:01')\n","                return pd.to_datetime(time_val, format='%H:%M:%S').strftime('%H:%M:%S')\n","            except (ValueError, TypeError):\n","                # If time cannot be parsed, return the original value\n","                return time_val\n","\n","    # Apply the conversion function to each entry in the column\n","    df['TransactionTime'] = df['TransactionTime'].apply(convert_to_24hr_format)\n","    \n","    # Convert time to categorical periods\n","    def categorize_time(time_str):\n","        try:\n","            time = pd.to_datetime(time_str, format='%H:%M:%S').time()\n","            if time < pd.to_datetime('06:00:00').time():\n","                return 4  # Late Night\n","            elif time < pd.to_datetime('12:00:00').time():\n","                return 1  # Morning\n","            elif time < pd.to_datetime('18:00:00').time():\n","                return 2  # Afternoon\n","            else:\n","                return 3  # Evening\n","        except (ValueError, TypeError):\n","            return 0  # Default to Morning if time cannot be parsed\n","\n","    df['TransactionTime'] = df['TransactionTime'].apply(categorize_time)\n","    \n","    # Map TransactionType\n","    df['TransactionType'] = df['TransactionType'].map({'Payment': 0, 'Purchase': 1, 'Withdrawal': 2, 'Transfer': 3})\n","\n","    # Convert MerchantID to its last digit\n","    df['MerchantID'] = df['MerchantID'].str.extract('(\\d+)').astype(int)\n","    \n","    # Gender mapping to 0 and 1\n","    df['Gender'] = df['Gender'].map({'Female': 0, 'Male': 1})\n","    \n","    # Map Terrorism to 1 for True and 0 for False\n","    df['Terrorism'] = df['Terrorism'].map({True: 1, False: 0})\n","\n","    # Fix TransactionDate: strip dashes and convert to integer, invalid dates treated as 0\n","    def process_transaction_date(date_str):\n","        try:\n","            # Convert valid date in format 'YYYY-MM-DD' to an integer by stripping the dashes\n","            return int(date_str.replace('-', ''))\n","        except (ValueError, AttributeError):\n","            # Handle invalid date formats and missing values\n","            return 0\n","\n","    # Apply the function to the TransactionDate column\n","    df['TransactionDate'] = df['TransactionDate'].apply(process_transaction_date)\n","\n","    \n","    # Email Domain extraction \n","    df['EmailDomain'] = df['EmailDomain'].str.extract('(@.*)')\n","    \n","    # Map EmailDomain to numerical values\n","    email_domain_mapping = {\n","    '@gmail.com': 1, '@outlook.com': 2, '@yahoo.com': 3,\n","    '@securemail.com': 4, '@tempmail.com': 5, '@disposable.com': 6\n","    }\n","    \n","\n","    # Extract the domain from the email and map it, default to 0 for others\n","    df['EmailDomain'] = df['EmailDomain'].apply(lambda x: email_domain_mapping.get(x, 0))\n","    \n","    # Impute missing values in remaining columns with the mean strategy\n","    imputer = SimpleImputer(strategy='mean')\n","    df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","\n","    return df\n","\n","# Example usage\n","x_train = preprocess(x_train)\n","x_test = preprocess(x_test)\n","\n","# Display the first few rows of the processed DataFrames\n","print(x_train.head())\n","print(x_test.head())\n","\n","x_train.to_csv('x_train_processed.csv', index=False)\n","x_test.to_csv('x_test_processed.csv', index=False)"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:31.473923Z","iopub.status.busy":"2024-09-15T01:53:31.473497Z","iopub.status.idle":"2024-09-15T01:53:31.481273Z","shell.execute_reply":"2024-09-15T01:53:31.479208Z","shell.execute_reply.started":"2024-09-15T01:53:31.473879Z"},"trusted":true},"outputs":[],"source":["# #PCA - Not suitable accuracy was lowered \n","# from sklearn.decomposition import PCA\n","# from sklearn.preprocessing import StandardScaler\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.metrics import accuracy_score\n","\n","# # Step 1: Standardize the data\n","# scaler = StandardScaler()\n","# x_train_scaled = scaler.fit_transform(x_train)\n","\n","# # Step 2: Apply PCA\n","# pca = PCA(n_components=0.95)  # Retain 95% variance\n","# x_train_pca = pca.fit_transform(x_train_scaled)\n","\n","# # Step 3: Train a classifier (Random Forest) on original and PCA-reduced data\n","# # Split the data into training and validation sets for both versions\n","# x_train_orig, x_val_orig, y_train_orig, y_val_orig = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","# x_train_pca_split, x_val_pca, y_train_pca, y_val_pca = train_test_split(x_train_pca, y_train, test_size=0.2, random_state=42)\n","\n","# # Random Forest on original data\n","# clf_orig = RandomForestClassifier(random_state=42)\n","# clf_orig.fit(x_train_orig, y_train_orig)\n","# y_pred_orig = clf_orig.predict(x_val_orig)\n","# accuracy_orig = accuracy_score(y_val_orig, y_pred_orig)\n","\n","# # Random Forest on PCA-reduced data\n","# clf_pca = RandomForestClassifier(random_state=42)\n","# clf_pca.fit(x_train_pca_split, y_train_pca)\n","# y_pred_pca = clf_pca.predict(x_val_pca)\n","# accuracy_pca = accuracy_score(y_val_pca, y_pred_pca)\n","\n","# print(f\"Accuracy on original data: {accuracy_orig:.4f}\")\n","# print(f\"Accuracy on PCA-reduced data: {accuracy_pca:.4f}\")\n"]},{"cell_type":"code","execution_count":129,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:31.483798Z","iopub.status.busy":"2024-09-15T01:53:31.483341Z","iopub.status.idle":"2024-09-15T01:53:31.503041Z","shell.execute_reply":"2024-09-15T01:53:31.501784Z","shell.execute_reply.started":"2024-09-15T01:53:31.483755Z"},"trusted":true},"outputs":[],"source":["# # Random Forrest test - finding the best value \n","\n","\n","# import pandas as pd\n","# from sklearn.model_selection import train_test_split, GridSearchCV\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.metrics import classification_report, log_loss, roc_auc_score, f1_score\n","\n","# def eval_model(model, x_train, y_train, x_val, y_val):\n","#     model.fit(x_train, y_train.values.ravel())  # Ensure y_train is 1D\n","#     y_val_pred = model.predict(x_val)\n","    \n","#     # Convert y_val to Series if it's a DataFrame\n","#     if isinstance(y_val, pd.DataFrame):\n","#         y_val = y_val.iloc[:, 0]\n","    \n","#     # Calculate metrics\n","#     auc = roc_auc_score(y_val, y_val_pred, multi_class='ovr') if len(y_val.unique()) > 2 else roc_auc_score(y_val, y_val_pred)\n","#     f1 = f1_score(y_val, y_val_pred, average='weighted')\n","#     ll = log_loss(y_val, model.predict_proba(x_val))\n","    \n","#     return ll, auc, f1\n","\n","# def random_forest_grid_search(x_train, y_train, x_test, test_size=0.2, random_state=42):\n","#     # Split the training data into training and validation sets\n","#     x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n","#         x_train, y_train, test_size=test_size, random_state=random_state\n","#     )\n","\n","#     # Convert y_train_split and y_val_split to 1D if they are DataFrames\n","#     if isinstance(y_train_split, pd.DataFrame):\n","#         y_train_split = y_train_split.iloc[:, 0]\n","#     if isinstance(y_val_split, pd.DataFrame):\n","#         y_val_split = y_val_split.iloc[:, 0]\n","    \n","#     # Define the parameter grid\n","#     param_grid = {\n","#         'n_estimators': [50, 200, 500],\n","#         'max_depth': [1, 3, 6, 10]\n","#     }\n","\n","#     # Create GridSearchCV object\n","#     grid_search = GridSearchCV(\n","#         estimator=RandomForestClassifier(random_state=43),\n","#         param_grid=param_grid,\n","#         cv=3,\n","#         scoring='f1_weighted',\n","#         n_jobs=-1,\n","#         verbose=2\n","#     )\n","\n","#     # Fit the model on the training data\n","#     grid_search.fit(x_train_split, y_train_split.values.ravel())  # Ensure y_train_split is 1D\n","    \n","#     # Print the best parameters and best score\n","#     print(f\"Best parameters found: {grid_search.best_params_}\")\n","#     print(f\"Best cross-validation score: {grid_search.best_score_}\")\n","\n","#     # Test the model on the validation set\n","#     best_model = grid_search.best_estimator_\n","#     ll, auc, f1 = eval_model(best_model, x_train_split, y_train_split, x_val_split, y_val_split)\n","\n","#     print(f\"Validation Log Loss: {ll:.4f}\")\n","#     print(f\"Validation AUC: {auc:.4f}\")\n","#     print(f\"Validation F1 Score: {f1:.4f}\")\n","\n","#     # Generate predictions on the test data\n","#     y_test_pred = best_model.predict(x_test)\n","#     y_test_pred_df = pd.DataFrame(y_test_pred, index=x_test.index, columns=['Prediction'])\n","\n","#     # Print a classification report on test data predictions\n","#     if 'y_test' in globals():\n","#         print(\"Classification Report on Test Data:\\n\", classification_report(y_val_split, y_test_pred))\n","#     else:\n","#         print(\"y_test is not provided for classification report.\")\n","\n","#     # Return predictions for further use\n","#     return y_test_pred_df\n","\n","# y_test_pred_df = random_forest_grid_search(x_train, y_train, x_test)\n","\n","# print(\"Test Predictions:\\n\", y_test_pred_df)\n"]},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:31.506352Z","iopub.status.busy":"2024-09-15T01:53:31.505917Z","iopub.status.idle":"2024-09-15T01:53:31.525695Z","shell.execute_reply":"2024-09-15T01:53:31.524058Z","shell.execute_reply.started":"2024-09-15T01:53:31.506296Z"},"trusted":true},"outputs":[],"source":["# # Using n_estimators=200, max_depth=10\n","\n","# import pandas as pd\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import classification_report, log_loss, roc_auc_score, f1_score\n","\n","# def eval_model(model, x_train, y_train, x_val, y_val):\n","#     model.fit(x_train, y_train.values.ravel())  # Ensure y_train is 1D\n","#     y_val_pred = model.predict(x_val)\n","    \n","#     # Convert y_val to Series if it's a DataFrame\n","#     if isinstance(y_val, pd.DataFrame):\n","#         y_val = y_val.iloc[:, 0]\n","    \n","#     # Calculate metrics\n","#     auc = roc_auc_score(y_val, y_val_pred, multi_class='ovr') if len(y_val.unique()) > 2 else roc_auc_score(y_val, y_val_pred)\n","#     f1 = f1_score(y_val, y_val_pred, average='weighted')\n","#     ll = log_loss(y_val, model.predict_proba(x_val))\n","    \n","#     return ll, auc, f1\n","\n","# def random_forest_evaluation(x_train, y_train, x_test, test_size=0.2, random_state=42):\n","#     # Separate the TransactionNumber for later use\n","#     transaction_numbers = x_test['TransactionNumber']\n","    \n","#     # Drop TransactionNumber for training and prediction\n","#     x_train_clean = x_train.drop(columns=['TransactionNumber'], errors='ignore')\n","#     x_test_clean = x_test.drop(columns=['TransactionNumber'], errors='ignore')\n","\n","#     # Split the training data into training and validation sets\n","#     x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n","#         x_train_clean, y_train, test_size=test_size, random_state=random_state\n","#     )\n","\n","#     # Convert y_train_split and y_val_split to 1D if they are DataFrames\n","#     if isinstance(y_train_split, pd.DataFrame):\n","#         y_train_split = y_train_split.iloc[:, 0]\n","#     if isinstance(y_val_split, pd.DataFrame):\n","#         y_val_split = y_val_split.iloc[:, 0]\n","    \n","#     model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=43, min_samples_split=10)\n","    \n","#     # Fit the model on the training data\n","#     model.fit(x_train_split, y_train_split.values.ravel())  # Ensure y_train_split is 1D\n","    \n","#     # Evaluate the model on the validation set\n","#     ll, auc, f1 = eval_model(model, x_train_split, y_train_split, x_val_split, y_val_split)\n","\n","#     print(f\"Validation Log Loss: {ll:.4f}\")\n","#     print(f\"Validation AUC: {auc:.4f}\")\n","#     print(f\"Validation F1 Score: {f1:.4f}\")\n","\n","#     # Generate predictions on the test data\n","#     y_test_pred = model.predict(x_test_clean)\n","\n","#     # Include TransactionNumber in the output and ensure it is an integer\n","#     y_test_pred_df = pd.DataFrame({\n","#         'TransactionNumber': transaction_numbers.astype(int),  # Convert to integer\n","#         'IsFraud': y_test_pred\n","#     })\n","\n","#     y_test_pred_df.to_csv('predictions.csv', index=False)\n","\n","#     return y_test_pred_df\n","\n","# y_test_pred_df = random_forest_evaluation(x_train, y_train, x_test)\n","\n","# print(\"Test Predictions:\\n\", y_test_pred_df.head())"]},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:31.527703Z","iopub.status.busy":"2024-09-15T01:53:31.527240Z","iopub.status.idle":"2024-09-15T01:53:31.549352Z","shell.execute_reply":"2024-09-15T01:53:31.547914Z","shell.execute_reply.started":"2024-09-15T01:53:31.527659Z"},"trusted":true},"outputs":[],"source":["# xg boost implementation (best implementation)\n","\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, log_loss, roc_auc_score, f1_score\n","\n","def xgboost_evaluation(x_train, y_train, x_test, test_size=0.2, random_state=42):\n","    # Separate the TransactionNumber for later use\n","    transaction_numbers = x_test['TransactionNumber']\n","    \n","    # Drop TransactionNumber for training and prediction\n","    x_train_clean = x_train.drop(columns=['TransactionNumber'], errors='ignore')\n","    x_test_clean = x_test.drop(columns=['TransactionNumber'], errors='ignore')\n","\n","    # Split the training data into training and validation sets\n","    x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n","        x_train_clean, y_train, test_size=test_size, random_state=random_state\n","    )\n","\n","    # Convert y_train_split and y_val_split to 1D if they are DataFrames\n","    if isinstance(y_train_split, pd.DataFrame):\n","        y_train_split = y_train_split.iloc[:, 0]\n","    if isinstance(y_val_split, pd.DataFrame):\n","        y_val_split = y_val_split.iloc[:, 0]\n","\n","    # Create the XGBoost model\n","    model = xgb.XGBClassifier(\n","        objective='binary:logistic',\n","        eval_metric='logloss',\n","        use_label_encoder=False,\n","        n_estimators=1000,\n","        max_depth=10,\n","        learning_rate=0.1,\n","        random_state=random_state\n","    )\n","    \n","    # Fit the model on the training data\n","    model.fit(x_train_split, y_train_split.values.ravel())  # Ensure y_train_split is 1D\n","\n","    # Evaluate the model on the validation set\n","    y_val_pred = model.predict(x_val_split)\n","    y_val_pred_proba = model.predict_proba(x_val_split)[:, 1]\n","    auc = roc_auc_score(y_val_split, y_val_pred_proba)\n","    f1 = f1_score(y_val_split, y_val_pred, average='weighted')\n","    ll = log_loss(y_val_split, y_val_pred_proba)\n","\n","    print(f\"Validation Log Loss: {ll:.4f}\")\n","    print(f\"Validation AUC: {auc:.4f}\")\n","    print(f\"Validation F1 Score: {f1:.4f}\")\n","\n","    # Generate predictions on the test data\n","    y_test_pred = model.predict(x_test_clean)\n","    \n","    # Include TransactionNumber in the output and ensure it is an integer\n","    y_test_pred_df = pd.DataFrame({\n","        'TransactionNumber': transaction_numbers.astype(int),  # Convert to integer\n","        'IsFraud': y_test_pred\n","    })\n","\n","    # Save predictions to a CSV file\n","    y_test_pred_df.to_csv('predday2.csv', index=False)\n","\n","    return y_test_pred_df\n","\n","y_test_pred_df = xgboost_evaluation(x_train, y_train, x_test)\n","\n","print(\"Test Predictions:\\n\", y_test_pred_df.head())"]},{"cell_type":"code","execution_count":132,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:31.551471Z","iopub.status.busy":"2024-09-15T01:53:31.550940Z","iopub.status.idle":"2024-09-15T01:53:31.574446Z","shell.execute_reply":"2024-09-15T01:53:31.573156Z","shell.execute_reply.started":"2024-09-15T01:53:31.551412Z"},"trusted":true},"outputs":[],"source":["# # hypertuning with xg boost\n","\n","# from sklearn.model_selection import GridSearchCV\n","# import xgboost as xgb\n","\n","# def xgboost_hyperparameter_tuning(x_train, y_train, x_test, test_size=0.2, random_state=42):\n","#     # Split the training data into training and validation sets\n","#     x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n","#         x_train, y_train, test_size=test_size, random_state=random_state\n","#     )\n","\n","#     # Define the parameter grid\n","#     param_grid = {\n","#         'n_estimators': [100, 300, 500],\n","#         'max_depth': [6, 10, 15],\n","#         'learning_rate': [0.01, 0.1, 0.2],\n","#         'subsample': [0.8, 1.0],\n","#         'colsample_bytree': [0.8, 1.0]\n","#     }\n","\n","#     # Create the XGBoost model\n","#     model = xgb.XGBClassifier(\n","#         objective='binary:logistic',\n","#         eval_metric='logloss',\n","#         use_label_encoder=False,\n","#         random_state=random_state\n","#     )\n","    \n","#     # Create GridSearchCV object\n","#     grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n","    \n","#     # Fit the model on the training data\n","#     grid_search.fit(x_train_split, y_train_split.values.ravel())  # Ensure y_train_split is 1D\n","    \n","#     # Print the best parameters and best score\n","#     print(f\"Best parameters found: {grid_search.best_params_}\")\n","#     print(f\"Best cross-validation score: {grid_search.best_score_}\")\n","\n","#     # Use the best model to make predictions on the test data\n","#     best_model = grid_search.best_estimator_\n","#     y_test_pred = best_model.predict(x_test)\n","    \n","#     # Include TransactionNumber in the output and ensure it is an integer\n","#     transaction_numbers = x_test['TransactionNumber'].astype(int)\n","#     y_test_pred_df = pd.DataFrame({\n","#         'TransactionNumber': transaction_numbers,\n","#         'IsFraud': y_test_pred\n","#     })\n","    \n","#     # Save predictions to a CSV file\n","#     y_test_pred_df.to_csv('xgboost_optimized_predictions.csv', index=False)\n","\n","#     return y_test_pred_df\n","\n","\n","# y_test_pred_df = xgboost_hyperparameter_tuning(x_train, y_train, x_test)\n","\n","# print(\"Test Predictions:\\n\", y_test_pred_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T01:53:31.577039Z","iopub.status.busy":"2024-09-15T01:53:31.576643Z"},"trusted":true},"outputs":[],"source":["\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5699027,"sourceId":9391360,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
